{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b77b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37feb340",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#setup GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#if gpus:\n",
    "#    try:\n",
    "#        # Currently, memory growth needs to be the same across GPUs\n",
    "#       for gpu in gpus:\n",
    "#            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "#        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "#    except RuntimeError as e:\n",
    "#        # Memory growth must be set before GPUs have been initialized\n",
    "#        print(e)\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f8686a",
   "metadata": {},
   "source": [
    "### Explore / Analyse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a634a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading files\n",
    "\n",
    "train_data = pd.read_csv(\"data/train.csv\")\n",
    "train_data\n",
    "\n",
    "# the column is not being displayed totally, so we will increase the width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ac8232",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.iloc[2]['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34deb4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[train_data.columns[2:]].iloc[2]\n",
    "\n",
    "# This shows that the following comment is not toxic at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727347ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display full comment by increasing the column width using pandas\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872be2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recheck the data with increased column width\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64608611",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve the information\n",
    "train_data.info()\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a728d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets check first 5 data with toxic or hate comments and LAUGH a BIT haha\n",
    "train_data[train_data['toxic'] == 1].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249842e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random sampling using pd.sample(n, frac,....)\n",
    "train_data[train_data['toxic'] == 1].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3072c545",
   "metadata": {},
   "source": [
    "### Process the Data using Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae9f817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using textvectorization for natural language, otherwise for normal string, use StringLookup\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "TextVectorization??\n",
    "\n",
    "#This layer has basic options for managing text in a Keras model. It transforms\n",
    "#a batch of strings (one example = one string) into either a list of token\n",
    "#indices (one example = 1D tensor of integer token indices) or a dense\n",
    "#representation (one example = 1D tensor of float values representing data\n",
    "#about the example's tokens). This layer is meant to handle natural language\n",
    "#inputs. To handle simple string inputs (categorical strings or pre-tokenized\n",
    "#strings) see `tf.keras.layers.StringLookup`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca622db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data['comment_text'] # comments\n",
    "y = train_data[train_data.columns[2:]].values #Features\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b4d73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y #numpy arrays to be passed onto the model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fb91c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying number of words for vectorization\n",
    "MAX_FEATURES = 200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d16691",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize = TextVectorization(max_tokens = MAX_FEATURES, output_mode = 'int', output_sequence_length = 1800)\n",
    "\n",
    "#inputs(total number of words, output_type, max input length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126f2157",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00aae7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize.adapt(X.values) # passing the comments as numpy array to the model using X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f620577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check the first 50 generated vocabs from the Text vectorization\n",
    "print(vectorize.get_vocabulary()[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db60df83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic data_test to check the location in the vector\n",
    "vectorize(\"Nice, what are you doing?\")[:5]\n",
    "\n",
    "#check the 20th word in the upper section \"are\", the following is stored in the Tensor dsiplayed below \n",
    "#\"520,40, 20, 7, 273\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f890452",
   "metadata": {},
   "source": [
    "### Creating the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bd3365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now vrctorizing the entire X values\n",
    "Vector_text = vectorize(X.values)\n",
    "Vector_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffb136e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Pre-shuffle the data and setting the batch size for training\n",
    "\n",
    "#MCSHBAP - map, cache, shuffle, batch, prefetch from tensor_slices, list_files -> instantiating the data pipeline\n",
    "data = tf.data.Dataset.from_tensor_slices((Vector_text, y))\n",
    "data = data.cache()\n",
    "data = data.shuffle(160000)\n",
    "data = data.batch(24)\n",
    "data = data.prefetch(8) # helps prevent bottlenecks\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05febc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.as_numpy_iterator().next()\n",
    "# first array is text in vectorized format.\n",
    "# 2nd array are the labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e48cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch, Y_batch = data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e97a7b4",
   "metadata": {},
   "source": [
    "### Split data into train, test, split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9229d8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(len(data)*.7) # partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7c006d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_batch.shape, Y_batch.shape)\n",
    "\n",
    "# 70%\n",
    "train = data.take(int(len(data)* .7))\n",
    "valid = data.skip(int(len(data)* .7)).take(int(len(data)* .2))\n",
    "test = data.skip(int(len(data)* .7)).skip(int(len(data)* .2)).take(int(len(data)* .1))\n",
    "\n",
    "print(f'The training sample is {len(train)}, Valid Samples is {len(valid)}, Test Set is {len(test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736d2802",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train.as_numpy_iterator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f38cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.next() # use this to see how the model learns batchwiswe (run again and again)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db6a2db",
   "metadata": {},
   "source": [
    "##  HOW IT WORKS:\n",
    "Go through a batch -> forward pass -> backward pass -> update the gradients -> next batch [.next()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b88b1f",
   "metadata": {},
   "source": [
    "## Build Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2944f97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Bidirectional, Dense, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19b4f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(MAX_FEATURES+1, 32, input_length = 1800))\n",
    "    \n",
    "    #GPU acceleration needed for LSTM layer should be tanh, defined by TENSORFLOW!!\n",
    "    model.add(Bidirectional(LSTM(32, activation = 'tanh'))) \n",
    "    # Bidirectional useful for NLP task for passing information both ways\n",
    "    \n",
    "    model.add(Dense(64, activation = 'elu'))\n",
    "    model.add(Dense(128, activation = 'elu'))\n",
    "    model.add(Dense(256, activation = 'elu'))\n",
    "    model.add(Dense(128, activation = 'elu'))\n",
    "    \n",
    "    #final_layer (24, 1800) (24, 6) -> the number of output as labels \"toxic, sever_toxic,.......\"\n",
    "    model.add(Dense(6, activation = 'sigmoid'))\n",
    "    model.compile(loss= 'BinaryCrossentropy', optimizer= 'Adam', metrics = ['acc'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7ec64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = predictor()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1612590a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n",
    "#mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "strategy = tf.distribute.MultiWorkerMirroredStrategy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89242ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a230d8b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "#checkpoint = keras.callbacks.ModelCheckpoint('ToxicPredict.h5', save_best_only = True)\n",
    "history = model.fit(train, epochs = 10, validation_data= valid, verbose = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43e8c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import pickle\n",
    "with open('./first_history', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)\n",
    "\n",
    "with open('./first_history', \"rb\") as file_pi:\n",
    "    history = pickle.load(file_pi)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d686b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 5))\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed83bbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('toxic_predict.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f130517",
   "metadata": {},
   "source": [
    "### predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e22f56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = vectorize(\"Are you Fucking Idiot\") # Basic check.\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a31d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(np.array[input_text])\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model(\"toxic_predict.h5\")\n",
    "model.predict(np.expand_dims(input_text,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44616bf0",
   "metadata": {},
   "source": [
    "### Test on TestSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d981af",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x, batch_y = test.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044d1ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(model.predict(batch_x) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa07964a",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69675cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy\n",
    "\n",
    "pre = Precision()\n",
    "rec = Recall()\n",
    "acc = CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505cb61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test.as_numpy_iterator():\n",
    "    x_true, y_true = batch\n",
    "    yhat = model.predict(x_true)\n",
    "    \n",
    "    y_true = y_true.flatten()\n",
    "    yhat = yhat.flatten()\n",
    "    \n",
    "    \n",
    "    pre.update_state(y_true, yhat)\n",
    "    rec.update_state(y_true, yhat)\n",
    "    acc.update_state(y_true, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c202a388",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Precision  :{pre.result().numpy()}')\n",
    "print(f'Recall  :{rec.result().numpy()}')\n",
    "print(f'Accuracy  :{acc.result().numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7834cd77",
   "metadata": {},
   "source": [
    "### USER INTERFACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7c05aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade h11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c9127c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model(\"toxic_predict.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899e044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# good text check\n",
    "text_check = vectorize('I will kill you without a doubt')\n",
    "\n",
    "res = model.predict(np.expand_dims(text_check, 0))\n",
    "print(res > 0.5)\n",
    "\n",
    "train_data.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4e8155",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Toxic check\n",
    "hate_check = vectorize('I will kill you and your family! you suck')\n",
    "res = model.predict(np.expand_dims(hate_check, 0))\n",
    "print(res)\n",
    "print(res>0.5)\n",
    "train_data.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4f60ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5459c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comment_interface(comment):\n",
    "    vectorize_comment = vectorize([comment])\n",
    "    results = model.predict(vectorize_comment)\n",
    "    \n",
    "    text = ''\n",
    "    for idx, col in enumerate(train_data.columns[2:]):\n",
    "        text += '{}: {}\\n'. format(col, results[0][idx]>0.5)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7937d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "interface = gr.Interface(fn = comment_interface,\n",
    "                        inputs = gr.inputs.Textbox(lines = 2, placeholder = 'write comment'),outputs = 'text')\n",
    "\n",
    "interface.launch(share = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283cf4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
